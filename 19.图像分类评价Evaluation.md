### Distance Measurement:
* Euclidean distance (L2 norm)
* Manhattan distance (L1 norm)
* $\alpha$ norm
$L_{\alpha} = \Big(\sum_i |p_i-q_i|^{\alpha}\Big)^{\frac{1}{\alpha}}$

### Voronoi Diagram
a partition of a plane into regions close to each of a given set of objects.
![](\images\voronoi.png)

### Confusion Matrix:
Multi-label Classifier

The figures show the confusion matrix with and without normalization by class support size (number of elements in each class). This kind of normalization can be interesting in case of class imbalance to have a more visual interpretation of which class is being misclassified.
![](\images\confusion.png)

### Receiver Operator Characteristic (ROC) Curve
* x-axis False Positive Rate
$\frac{FP}{FP+TN}$
* y-axis True Positive Rate 
$\frac{TP}{TP+FN}$ i.e. Recall
* diagonal line: random guess
* doesn't affect by imbalance data (each metric use only one label data to measure)
![](\images\roc.png)
![](\images\roc1.png)

### PR Curve
Precision Recall Curve

![](\images\PRcurve.png)

Precision – Recall  is the best option to evaluate Level 1 similarity

When retrieval is based on presence of categories (e.g. Level 2 semantic contents) the problem is one of supervised classification – use confusion matrix.
