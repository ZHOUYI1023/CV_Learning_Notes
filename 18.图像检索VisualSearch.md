## Task Definition of Visual Search:
* We have:
    * a database of images
    * algorithm to represent the images 
    * algorithm to calculate similarity score
* Preprocess:
    * represent every image in database into N-dimensional descriptors
    * we can directly use the descriptors to replace the images
* Input: a query image
* Process:
    * represent the image in feature space
    * calculate the distance score from other images in database
* Output: ranked images based on similarity score 

## Methods:
### 1. Global Color (-Only) Histogram
RGB space is quantitized into bins
Normalized the results to get the distribution

suppose $q$ bins for every color channel, then $q^3$ bins in total
each pixel is represented by a vector $[r_q, g_q, b_q]$ 
$r_q,g_q,b_q \isin [0, q-1]$

Notice [0,0,q-1] is completely different from [0,1,0]

encode the vector into a single number in base $q$, different numbers represent independent dimensions

Then there are $q^3$ bins in total
We make a histogram with x-axis as the index of bin, and y-axis as the number of pixels fall in to this bin

Finally, we could encode the histogram into a 1 dimensional vector with $q^3$ entries for each image.

### 2. Grid + Color + PCA 
Intuition: add some spatial information (add one dimension, to get a 2 dimensional desciptor)

Decompose the image into $x \times y$ cells, and concatenate each descriptor to form a descriptor with size of $(x \cdot y) \times q^3$ (column vector).  Do some dimension reduction through PCA

Project data to basis of first N eigenvectors 

Then, we can represent the images in a reduced feature space. 
When a new query comes, we can calculate the Distance from every images in database.


### 3. Edge Orientation Histogram
Intuition: texture/edges are discriminitive
use Sobel filter to calculate the edge orientation 
Only count orientations from strong edges
Quantize orientation into 8 bins
Then, the same process as above

### 4. EOH + Mean Color
Intuition: use spatial distribution of both edeges and color

Concatenate  two vectors to formulate a joint desciptor, finally ,calculate the Euclidean distance.

### Limitations of Grid Methods
* Coarse grids do not precisely cover the object -> poor discrimination
* Fine grids yield many cells-> poor compactness
* Grids are sensitive to translation, rotation, and scaling of objects


## Semantic Gap
How to define similarity?
* Level 1: Similar low-level features (texture, colour)
* Level 2: Similar semantic contents (object, activity)
* Level 3: High-level concepts (war, comedy, news)

CBIR = Content Based Image Retrieval (visual search is a form of CBIR)

## Evaluating Visual Search
‘top N’ results: 
For every query image, compute the metric based on the correctness of the top N most similar images

![](\images\PrecisionRecall.png)


Precision Recall Curve

![](\images\PRcurve.png)

$AP = \frac{\sum_{n=1}^{M}P(n)\times rel(n)}{N}$
where M is the datasize, N is the total number of relevent documents

MAP is AP averaged over all queries

Precision – Recall  is the best option to evaluate Level 1 similarity

When retrieval is based on presence of categories (e.g. Level 2 semantic contents) the problem is one of supervised classification – use confusion matrix.