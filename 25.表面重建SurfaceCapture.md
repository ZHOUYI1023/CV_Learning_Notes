# Surface Capture  
## Camera Calibration
get intrinsics K and recover radial distortion
## Wand Based Calibration
An Eigenmodel in RGB space yields a good mask of the marker
![](\images\wand.png)
## RANSAC fitting of circular model
1. Run edge detection over binary mask and threshold
2. Pick 3 edge pixels at random
3. Compute centre of circle whose circumference touches all three of the points
4. Count up the number of pixels the fitted circle passes through
5. Repeat a large number of times and use the circle parameters (a,b,r) that maximise the count in 4
![](\images\circle.png)
## Pairwise Calibration
Find the extrinsics for the cameras in a pairwise fashion
1. Compute F using correspondences between views
2. Rearrange F and K to get E
3. Decompose E to get extrinsics R and T.

## Global Bundle Adjustment
![](\images\reproject.png)

## Computing the silhouette
An Eigenmodel can be trained using the blue background.  
An appropriate threshold on the Mahalanobis distance can be determined via ROC curve analysis on a few sample frames.
## Computing the visual hull
```
For each voxel (x,y,z) in the capture volume
	Let counter=0
	For each calibrated camera
		Project (x,y,z) to (u,v)
		If (u,v) is set, then counter =counter+1
	End
	If counter >=threshold * , then voxel is part of hull
End
* Threshold might be set between 60-100% of camera count
```
## Meshing the Hull
The voxel model is converted into a mesh model using Marching Cubes
* For each cube, we have 8 vertices with 2 possible states each (inside or outside).
* This gives us 28 possible patterns = 256 cases.
* Use symmetries to reduce problem from 256 to 15 cases.
![](\images\marchingcube.png)
* Use vertex bit mask to create an index for each case based on the state of the vertexes. 
* Use index to lookup list of edges intersected.
![](\images\marchingcube1.png)
* Use densities to interpolate edge intersections
![](\images\marchingcube2.png)
* Determine surface normal
Surface normals need to be determined for shading
    * calculate normal for each cube vertex
    * interpolate the normals at the vertices of the triangles
![](\images\marchingcube3.png)
* Output the triangle vertices and vertex normals

## Texturing the Mesh
Each polygon is assigned a piece of texture cut from one of the cameraâ€™s images.
* Rays are projected from each polygon in the direction of the surface normal.
* The dot project of the normal with the camera optical axis reveals the camera most directly facing the polygon.
* Simple depth tests confirm the visibility of each camera


