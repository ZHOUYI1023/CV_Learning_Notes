## Vector Quantization
One way to combine descriptors is to group them into visually similar clusters.
Divide up (quantize) the vector space in which descriptors are embedded.
* Feature space divided into k regions
* Thus each descriptor is mapped to a label {1…k}  we called this a CODEWORD
* The DICTIONARY of codewords is {1..k}
![](\images\vector_quantization.png)

## Bag of Visual Words (BoVW) 
Vector Quantization(VQ) is often referred to as Bag of Visual Words (BoVW)
1. Feature extraction
    * regular grid
    * interest point detector
2. Describe the point and assembly into feature space
3. Clustering is a common method for learning a codebook(visual vocabulary) 
    * Use K-means to quantize the feature space into k bins
4. Represent images by codeword(visual word) frequency histogram 

利用BoVW模型表示图像，获得图像的全局直方图表示，主要有四个关键步骤：

1. 图像局部特征提取（Image Local Features Extrication）。根据具体应用考虑，综合考虑特征的独特性、提取算法复杂性、效果好坏等选择特征。利用局部特征提取算法，从图像中提取局部特征。
2. 视觉词典构造（Visual Dictionary Construction）。一般是从图像库中选取一部分来自不同场景或类别的图像来组成训练图像集，并提取其局部特征,然后对训练图像的所有局部特征向量通过适当的去冗余处理得到一些有代表性的特征向量,将其定义为视觉单词。通常所采用的处理方法是对训练图像的所有局部特征向量进行聚类分析，将聚类中心定义为视觉单词。所有视觉单词组成视觉词典，用于图像的直方图表示。
3. 特征向量量化(Feature Vector Quantization)。BoVW模型采用向量量化技术实现。现对图像局部特征的编码。向量量化结果是将图像的局部特征向量量化为视觉单词中与其距离最相似的视觉单词。向量量化过程实际上是一个搜索过程,通常采用最近邻搜索算法，搜索出与图像局部特征向量最为匹配的视觉单词。
4. 用视觉单词直方图表示图像，也称为量化编码集成(Pooling)。一幅图像的所有局部特征向量被量化后，可统计出视觉词典中每个视觉单词在该图像中出现的频数，得到一个关于视觉单词的直方图，其本质是上一步所得量化编码的全局统计结果,是按视觉单词索引顺序组成的一个数值向量（各个元素的值还可以根据一定的规则进行加权）。该向量即为图像的最终表示形式。
![](\images\bovw1.png)
![](\images\bovw2.png)

## K-means Clustering
Unsupervised Clustering
k is the prior parameter

Process:
* step 1: Choose k initial centroids at random
* step 2: Compute point-to-cluster-centroid distances of all observations to each centroid
* step 3: Two ways to proceed
    * Batch update — Assign each observation to the cluster with the closest centroid.
    * Online update — Individually assign observations to a different centroid if the reassignment decreases the sum of the within-cluster, sum-of-squares point-to-cluster-centroid distances.
* step 4: Compute the average of the observations in each cluster to obtain k new centroid locations.
* step 5: Repeat steps 2 through 4 until cluster assignments do not change, or the maximum number of iterations is reached.

The results may fail due to
* poor choice of k
* poor choice of initial centriods

### BoVW Similarity
* Euclidean distance 
* We should remove the most frequently occurring codewords (“stopwords”) e.g. top 5% to prevent distortion of distance measure 

TF-IDF Score
如果某个词或短语在一篇文章中出现的频率TF高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。
The rarer the codeword, the more discriminative it is.
Term Frequency (TF) – the probability of a codeword (term) in the document occurring.
表示一个给定词语w在一篇给定文档d中出现的频率
$$p(w|d)=\frac{\text{count of w occurrence in image d}}{\text{total codewords in image d}}$$

Inverse Document Frequency (IDF) – the probability of a document containing the codeword (term), in the dataset.
$$p(w)=\log\frac{\text{total number of images in database}}{\text{total number of images containing w}}$$
我们认为一个词越集中出现在某一类文档，它对这类文档的分类越有贡献，那么当一个词分布太散了，那他对文档归类的作用也不那么大了。

The TF-IDF relevance score is TF x IDF, i.e. $p(w|d) p(w)$ 

## VLAD
VQ is a coarse representation
* Simply a count of codewords within each cluster
* Information on feature’s position within cluster lost.

Vector of Locally Aggregated Descriptors (VLAD) 
* starts by performing k-means to VQ feature space as before
* but instead of building a frequency histogram, aggregates 	    feature distances from the cluster centroid.
* VLAD descriptor is a k x d vector, 
    * where k=cluster count (usually coarse ~64-128 clusters), 
	* d=dimension of feature space
![](\images\vlad.png)

Process
1. Initialise a vector of residuals for each cluster to zero
2. For each keypoint’s descriptor, find closest cluster
3. Subtract feature from that cluster’s centroid to get residual
4. Add this feature’s residual to cluster’s residual vector
5. Concatenate residuals of all clusters and normalise

VLAD可以理解为是BOF和fisher vector的折中
* BOF是把特征点做kmeans聚类，然后用离特征点最近的一个聚类中心去代替该特征点，损失较多信息；
* Fisher vector是对特征点用GMM建模，GMM实际上也是一种聚类，只不过它是考虑了特征点到每个聚类中心的距离，也就是用所有聚类中心的线性组合去表示该特征点，在GMM建模的过程中也有损失信息；
* VLAD像BOF那样，只考虑离特征点最近的聚类中心，VLAD保存了每个特征点到离它最近的聚类中心的距离;像Fisher vector那样，VLAD考虑了特征点的每一维的值，对图像局部信息有更细致的刻画；而且VLAD特征没有损失信息。